{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Results Summarizer\n",
    "\n",
    "#### This notebook cell finds all CSV files matching the pattern `results_*.csv` in the specified directory,\n",
    "#### extracts the matrix size from the filename, calculates the mean and standard deviation of the\n",
    "#### 'Time Taken (s)' column for each file, and prints a summary line in the format:\n",
    "#### `mean1 ± std1 & mean2 ± std2 & ...` sorted by matrix size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:143: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:143: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_35384\\4293335688.py:143: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  group to capture the matrix size number (e.g., '_(\\d+)\\.csv$').\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import warnings\n",
    "import math\n",
    "from decimal import Decimal, ROUND_HALF_UP, getcontext\n",
    "from typing import List, Tuple, Dict, Optional, Set\n",
    "\n",
    "# --- Helper Function for Formatting ---\n",
    "# (Keep this function as is, it's complex but self-contained)\n",
    "def format_mean_std(mean: float, std: float, default_precision: int = 6) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Formats mean and standard deviation according to scientific rounding rules.\n",
    "\n",
    "    Args:\n",
    "        mean (float): The mean value.\n",
    "        std (float): The standard deviation.\n",
    "        default_precision (int): Fallback precision if std is zero or non-finite.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (formatted_mean_str, formatted_std_str)\n",
    "    \"\"\"\n",
    "    # Ensure inputs are finite numbers\n",
    "    if not np.isfinite(mean) or not np.isfinite(std):\n",
    "        warnings.warn(f\"Non-finite input detected: mean={mean}, std={std}. Returning 'NaN'.\")\n",
    "        return \"NaN\", \"NaN\"\n",
    "\n",
    "    # Handle std == 0 case: Format mean reasonably, std is exactly 0.\n",
    "    if std == 0:\n",
    "        # Determine a reasonable precision for the mean if std is 0\n",
    "        mean_dec = Decimal(str(mean))\n",
    "        if mean_dec == mean_dec.to_integral_value(): # Looks like an integer\n",
    "             mean_fmt = f\"{int(mean)}\"\n",
    "             std_fmt = \"0\"\n",
    "        elif abs(mean) < 1e-4 and mean != 0: # Small number, use scientific? Or just default f\n",
    "             mean_fmt = f\"{mean:.{default_precision}g}\" # Use 'g' for auto sci/fixed\n",
    "             # Match decimal places if possible, otherwise use '0'\n",
    "             if 'e' in mean_fmt or 'E' in mean_fmt:\n",
    "                  std_fmt = \"0\" # Can't easily match sci notation '0'\n",
    "             elif '.' in mean_fmt:\n",
    "                  num_decimals = len(mean_fmt.split('.')[-1])\n",
    "                  std_fmt = f\"{0.0:.{num_decimals}f}\"\n",
    "             else: # Should not happen if not integer, but fallback\n",
    "                   std_fmt = \"0\"\n",
    "        else: # General case or large numbers with decimals\n",
    "             # Use default precision for mean when std is zero\n",
    "             mean_fmt = f\"{mean:.{default_precision}f}\"\n",
    "             # Ensure std has same number of decimal places if possible\n",
    "             if '.' in mean_fmt:\n",
    "                 num_decimals = len(mean_fmt.split('.')[-1])\n",
    "                 std_fmt = f\"{0.0:.{num_decimals}f}\"\n",
    "             else: # Mean formatted as integer or sci notation\n",
    "                 std_fmt = \"0\"\n",
    "\n",
    "        return mean_fmt, std_fmt\n",
    "\n",
    "    # --- Determine significant figures for std using Decimal ---\n",
    "    try:\n",
    "        # Use string conversion for Decimal to avoid float representation issues\n",
    "        std_dec = Decimal(str(std))\n",
    "        if std_dec <= 0: # Should handle std==0 above, this catches negative std?\n",
    "             raise ValueError(\"Standard deviation must be positive.\")\n",
    "\n",
    "        # Find the exponent of the first significant digit (most significant digit's position)\n",
    "        exponent = std_dec.adjusted()\n",
    "\n",
    "        # Find the first significant digit's value\n",
    "        sci_notation = f\"{std_dec:e}\" # e.g., '1.2345e-3' or '1.2345e+2'\n",
    "        first_digit_char = sci_notation.lstrip('-')[0] # Handle negative numbers (though std shouldn't be)\n",
    "        if not first_digit_char.isdigit():\n",
    "             raise ValueError(f\"Could not extract first digit from std: {std}\")\n",
    "        first_digit = int(first_digit_char)\n",
    "\n",
    "        # Determine number of significant figures (k) for std\n",
    "        k = 2 if first_digit == 1 else 1\n",
    "\n",
    "        # --- Round std to k significant figures ---\n",
    "        # Position of the least significant digit needed for std\n",
    "        # math.floor(math.log10(abs(std))) gives the exponent of the leading digit\n",
    "        std_exponent = math.floor(math.log10(abs(std))) # Position of leading digit power of 10\n",
    "\n",
    "        # The decimal place *index* to round to is (std_exponent - (k - 1))\n",
    "        rounding_decimal_place = std_exponent - (k - 1)\n",
    "\n",
    "        # Use Decimal quantize for rounding std\n",
    "        quantizer_std = Decimal('1e' + str(rounding_decimal_place))\n",
    "        rounded_std_dec = std_dec.quantize(quantizer_std, rounding=ROUND_HALF_UP)\n",
    "\n",
    "        # --- Determine decimal places for mean ---\n",
    "        # The mean should be rounded to the same decimal place as the rounded std.\n",
    "        decimal_places = max(0, -rounding_decimal_place)\n",
    "\n",
    "        # --- Round mean to the same decimal place ---\n",
    "        mean_dec = Decimal(str(mean))\n",
    "        if decimal_places > 0:\n",
    "            mean_quantizer = Decimal('1e-' + str(decimal_places))\n",
    "        else:\n",
    "            # Round to the nearest integer (or 10, 100 etc. if std was large)\n",
    "            mean_quantizer = quantizer_std # Use the same quantizer as std\n",
    "\n",
    "        rounded_mean_dec = mean_dec.quantize(mean_quantizer, rounding=ROUND_HALF_UP)\n",
    "\n",
    "        # --- Format as strings ---\n",
    "        # Use '.Xf' format specifier for consistent decimal places\n",
    "        mean_fmt = f\"{rounded_mean_dec:.{decimal_places}f}\"\n",
    "        std_fmt = f\"{rounded_std_dec:.{decimal_places}f}\"\n",
    "\n",
    "        return mean_fmt, std_fmt\n",
    "\n",
    "    except ValueError as ve: # Catch specific errors like negative std or digit extraction issue\n",
    "        warnings.warn(f\"Value error during dynamic rounding for mean={mean}, std={std}: {ve}. Falling back to default precision.\")\n",
    "        mean_fmt = f\"{mean:.{default_precision}g}\"\n",
    "        std_fmt = f\"{std:.{default_precision}g}\"\n",
    "        return mean_fmt, std_fmt\n",
    "    except Exception as e: # General catch-all\n",
    "        warnings.warn(f\"Unexpected error during dynamic rounding for mean={mean}, std={std}: {type(e).__name__} - {e}. Falling back to default precision.\")\n",
    "        mean_fmt = f\"{mean:.{default_precision}g}\"\n",
    "        std_fmt = f\"{std:.{default_precision}g}\"\n",
    "        return mean_fmt, std_fmt\n",
    "\n",
    "\n",
    "# --- Main Processing Function ---\n",
    "def process_and_format_results(\n",
    "    results_folder: str,\n",
    "    file_pattern: str = 'results_*_[0-9]*.csv',\n",
    "    time_column_name: str = 'Time Taken (s)',\n",
    "    include_sizes: Optional[Set[int]] = None,\n",
    "    min_size_to_include: Optional[int] = 256, # Based on your original filtering logic\n",
    "    default_output_precision: int = 6,\n",
    "    output_separator: str = \" & \",\n",
    "    verbose: bool = True,\n",
    "    print_summary: bool = True,\n",
    "    print_output: bool = True\n",
    ") -> Tuple[str, Dict[int, Tuple[float, float]], List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Processes CSV result files, calculates mean/std, formats them, and returns results.\n",
    "\n",
    "    Args:\n",
    "        results_folder (str): Path to the directory containing the CSV files.\n",
    "        file_pattern (str): Glob pattern to match result files. Should contain a\n",
    "                            group to capture the matrix size number (e.g., '_(\\d+)\\.csv$').\n",
    "        time_column_name (str): Name of the column containing time data in the CSVs.\n",
    "        include_sizes (Optional[Set[int]]): A set of specific matrix sizes to include.\n",
    "                                             If None, size filtering is based only on\n",
    "                                             min_size_to_include.\n",
    "        min_size_to_include (Optional[int]): Minimum matrix size to include in the\n",
    "                                             final output. If None, no minimum size filter.\n",
    "                                             Defaults to 256 based on original script logic.\n",
    "        default_output_precision (int): Fallback precision for format_mean_std.\n",
    "        output_separator (str): Separator used to join the formatted results for the final string.\n",
    "        verbose (bool): If True, print detailed processing steps and warnings.\n",
    "        print_summary (bool): If True, print the processing summary (counts of files).\n",
    "        print_output (bool): If True, print the final formatted output string.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - str: The final formatted output string (e.g., for LaTeX).\n",
    "        - Dict[int, Tuple[float, float]]: Dictionary mapping matrix size to (raw mean, raw std).\n",
    "        - List[str]: List of base filenames successfully processed.\n",
    "        - List[str]: List of base filenames skipped (with reason).\n",
    "    \"\"\"\n",
    "    # Set Decimal context precision (optional, but good practice if needed)\n",
    "    # getcontext().prec = 28 # Default is usually sufficient\n",
    "\n",
    "    results: Dict[int, Tuple[float, float]] = {}\n",
    "    processed_files: List[str] = []\n",
    "    skipped_files: List[str] = []\n",
    "\n",
    "    # Construct the full search path\n",
    "    search_path = os.path.join(results_folder, file_pattern)\n",
    "\n",
    "    # Find all matching files\n",
    "    try:\n",
    "        csv_files = glob.glob(search_path)\n",
    "    except Exception as e:\n",
    "         print(f\"Error during file search with pattern '{search_path}': {e}\")\n",
    "         return \"\", {}, [], []\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"Warning: No files found matching the pattern '{search_path}' in directory '{os.path.abspath(results_folder)}'\")\n",
    "        return \"\", {}, [], []\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Found {len(csv_files)} potential result files matching '{file_pattern}' in '{results_folder}'...\")\n",
    "\n",
    "    # Compile regex for efficiency if pattern is complex (simple here)\n",
    "    size_regex = re.compile(r'_(\\d+)\\.csv$') # Assumes size is numbers before .csv\n",
    "\n",
    "    for filepath in csv_files:\n",
    "        base_filename = os.path.basename(filepath)\n",
    "        if verbose:\n",
    "            print(f\"Processing '{base_filename}'...\")\n",
    "\n",
    "        match = size_regex.search(base_filename)\n",
    "        if not match:\n",
    "            if verbose:\n",
    "                print(f\"  Warning: Could not extract matrix size number from filename '{base_filename}'. Skipping.\")\n",
    "            skipped_files.append(f\"{base_filename} (no size match)\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            matrix_size = int(match.group(1))\n",
    "            # --- Filtering Logic ---\n",
    "            if include_sizes is not None and matrix_size not in include_sizes:\n",
    "                 if verbose:\n",
    "                     print(f\"  Info: Skipping size {matrix_size} as it's not in the include_sizes set.\")\n",
    "                 skipped_files.append(f\"{base_filename} (size {matrix_size} not in include_sizes)\")\n",
    "                 continue\n",
    "            if min_size_to_include is not None and matrix_size < min_size_to_include:\n",
    "                if verbose:\n",
    "                    print(f\"  Info: Skipping size {matrix_size} as it's below min_size_to_include ({min_size_to_include}).\")\n",
    "                skipped_files.append(f\"{base_filename} (size {matrix_size} < {min_size_to_include})\")\n",
    "                continue\n",
    "            # --- End Filtering ---\n",
    "\n",
    "        except ValueError:\n",
    "            if verbose:\n",
    "                print(f\"  Warning: Extracted size '{match.group(1)}' is not a valid integer in filename '{base_filename}'. Skipping.\")\n",
    "            skipped_files.append(f\"{base_filename} (invalid size '{match.group(1)}')\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "\n",
    "            # --- Data Validation ---\n",
    "            if df.empty:\n",
    "                if verbose:\n",
    "                    print(f\"  Warning: File '{base_filename}' is empty. Skipping.\")\n",
    "                skipped_files.append(f\"{base_filename} (empty file)\")\n",
    "                continue\n",
    "            if time_column_name not in df.columns:\n",
    "                if verbose:\n",
    "                    print(f\"  Error: Column '{time_column_name}' not found in '{base_filename}'. Skipping.\")\n",
    "                skipped_files.append(f\"{base_filename} (missing column '{time_column_name}')\")\n",
    "                continue\n",
    "\n",
    "            # --- Calculation ---\n",
    "            times = pd.to_numeric(df[time_column_name], errors='coerce')\n",
    "            num_original = len(times)\n",
    "            num_null_before = times.isnull().sum()\n",
    "\n",
    "            if num_null_before == num_original:\n",
    "                 if verbose:\n",
    "                     print(f\"  Error: Column '{time_column_name}' in '{base_filename}' contains no valid numeric data. Skipping.\")\n",
    "                 skipped_files.append(f\"{base_filename} (no numeric data in column)\")\n",
    "                 continue\n",
    "            elif num_null_before > 0:\n",
    "                 if verbose:\n",
    "                     print(f\"  Warning: Found and ignored {num_null_before} non-numeric value(s) in '{time_column_name}' column of '{base_filename}'.\")\n",
    "\n",
    "            times = times.dropna() # Remove NaNs coerced from non-numeric values\n",
    "            if times.empty:\n",
    "                if verbose:\n",
    "                    print(f\"  Warning: After handling non-numeric values, no valid time data remains in '{base_filename}'. Skipping.\")\n",
    "                skipped_files.append(f\"{base_filename} (no valid data after dropna)\")\n",
    "                continue\n",
    "\n",
    "            mean_time = times.mean()\n",
    "            # Calculate std dev. Use ddof=1 (sample std dev).\n",
    "            # Handle cases with 0 or 1 data point where std dev is undefined or zero.\n",
    "            if len(times) > 1:\n",
    "                 std_dev_time = times.std(ddof=1)\n",
    "                 if pd.isna(std_dev_time): # Should only happen if input had NaNs not caught? Or weird data.\n",
    "                    std_dev_time = 0.0\n",
    "                    if verbose:\n",
    "                        print(f\"  Info: Std deviation calculated as NaN for size {matrix_size}. Setting to 0.0.\")\n",
    "            else: # len(times) == 1\n",
    "                 std_dev_time = 0.0 # Std dev of a single point is 0\n",
    "                 if verbose:\n",
    "                     print(f\"  Info: Only one data point found for size {matrix_size}. Standard deviation set to 0.0.\")\n",
    "\n",
    "\n",
    "            # --- Store Raw Results ---\n",
    "            if matrix_size in results:\n",
    "                 if verbose:\n",
    "                     print(f\"  Warning: Duplicate matrix size {matrix_size} found (from '{base_filename}'). Overwriting previous result.\")\n",
    "\n",
    "            results[matrix_size] = (float(mean_time), float(std_dev_time)) # Ensure storing as float\n",
    "            processed_files.append(base_filename)\n",
    "\n",
    "        except pd.errors.EmptyDataError:\n",
    "            if verbose:\n",
    "                print(f\"  Warning: File '{base_filename}' is empty or contains only headers (pandas EmptyDataError). Skipping.\")\n",
    "            skipped_files.append(f\"{base_filename} (pandas EmptyDataError)\")\n",
    "        except FileNotFoundError:\n",
    "             # This shouldn't happen inside the loop as glob found it, but just in case\n",
    "             print(f\"  Error: File '{filepath}' vanished before processing? Skipping.\")\n",
    "             skipped_files.append(f\"{base_filename} (FileNotFoundError during processing)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing file '{base_filename}': {type(e).__name__} - {e}. Skipping.\")\n",
    "            skipped_files.append(f\"{base_filename} (processing error: {type(e).__name__})\")\n",
    "\n",
    "    # --- Final Output Generation ---\n",
    "    if print_summary:\n",
    "        print(\"\\n--- Processing Summary ---\")\n",
    "        print(f\"Searched in: {os.path.abspath(results_folder)}\")\n",
    "        print(f\"Using pattern: {file_pattern}\")\n",
    "        print(f\"Attempted to process {len(csv_files)} files.\")\n",
    "        print(f\"Successfully processed data for {len(results)} unique matrix sizes from {len(processed_files)} files.\")\n",
    "        if skipped_files:\n",
    "            print(f\"Skipped {len(skipped_files)} files/entries.\")\n",
    "            if verbose or len(skipped_files) < 10:\n",
    "                 print(\"  Skipped items list:\", skipped_files)\n",
    "            else:\n",
    "                 print(f\"  Example skipped items: {skipped_files[:5]}... (list truncated)\")\n",
    "        print(\"--- End Summary ---\")\n",
    "\n",
    "\n",
    "    final_output = \"\"\n",
    "    if not results:\n",
    "        print(\"\\nNo valid data was processed. Cannot generate output line.\")\n",
    "    else:\n",
    "        # Sort results by matrix size\n",
    "        sorted_sizes = sorted(results.keys())\n",
    "\n",
    "        # Format the output strings using the dynamic rounding function\n",
    "        output_parts = []\n",
    "        if verbose:\n",
    "            print(\"\\n--- Applying Scientific Dynamic Rounding (std determines mean precision) ---\")\n",
    "\n",
    "        for size in sorted_sizes:\n",
    "            # Filtering based on min_size_to_include is already done during file processing loop\n",
    "            mean, std = results[size]\n",
    "            try:\n",
    "                # Apply the dynamic rounding function\n",
    "                formatted_mean, formatted_std = format_mean_std(mean, std, default_output_precision)\n",
    "                # Format for LaTeX output: $mean \\pm std$\n",
    "                formatted_result = f\"${formatted_mean} \\\\pm {formatted_std}$\"\n",
    "                output_parts.append(formatted_result)\n",
    "                if verbose:\n",
    "                    print(f\"  Size {size}: Raw=({mean:.6g} ± {std:.6g}) -> Formatted={formatted_result}\")\n",
    "            except Exception as e:\n",
    "                 print(f\"  Error formatting result for size {size} (Mean={mean}, Std={std}): {type(e).__name__} - {e}. Adding placeholder.\")\n",
    "                 # Add a placeholder or skip\n",
    "                 output_parts.append(f\"$ERR \\\\pm ERR$\") # Placeholder for error\n",
    "\n",
    "        # Join the parts into the final output line\n",
    "        final_output = output_separator.join(output_parts)\n",
    "\n",
    "        if print_output:\n",
    "            print(\"\\n--- Results ---\")\n",
    "            # Display sizes actually included in the final string\n",
    "            included_sizes_in_output = sorted_sizes # Since filtering happened before this loop\n",
    "            print(\"Matrix Sizes Included in Output:\", included_sizes_in_output)\n",
    "            print(f\"\\nFinal Output Line (using separator '{output_separator}'):\")\n",
    "            print(final_output)\n",
    "\n",
    "    # Return the formatted string, raw data, and file lists\n",
    "    return final_output, results, processed_files, skipped_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\python\\basic\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_python_128.csv (size 128 < 256)', 'results_python_16.csv (size 16 < 256)', 'results_python_2.csv (size 2 < 256)', 'results_python_32.csv (size 32 < 256)', 'results_python_4.csv (size 4 < 256)', 'results_python_64.csv (size 64 < 256)', 'results_python_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$3.69 \\pm 0.05$ & $30.2 \\pm 0.4$ & $248 \\pm 3$ & $2350 \\pm 30$ & $19710 \\pm 40$ & $173900 \\pm 900$\n",
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\python\\numpy\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_python_numpy_128.csv (size 128 < 256)', 'results_python_numpy_16.csv (size 16 < 256)', 'results_python_numpy_2.csv (size 2 < 256)', 'results_python_numpy_32.csv (size 32 < 256)', 'results_python_numpy_4.csv (size 4 < 256)', 'results_python_numpy_64.csv (size 64 < 256)', 'results_python_numpy_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.0003 \\pm 0.0004$ & $0.029 \\pm 0.002$ & $0.021 \\pm 0.015$ & $0.04 \\pm 0.03$ & $0.26 \\pm 0.04$ & $1.87 \\pm 0.13$\n",
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_basic_O0\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_2.csv (size 2 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_4.csv (size 4 < 256)', 'results_c_64.csv (size 64 < 256)', 'results_c_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.02474 \\pm 0.00005$ & $0.224 \\pm 0.003$ & $2.7 \\pm 0.2$ & $97 \\pm 8$ & $921 \\pm 12$ & $7300 \\pm 400$\n",
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_basic_O1\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_2.csv (size 2 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_4.csv (size 4 < 256)', 'results_c_64.csv (size 64 < 256)', 'results_c_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.00710 \\pm 0.00008$ & $0.150 \\pm 0.017$ & $2.16 \\pm 0.07$ & $88 \\pm 9$ & $782 \\pm 2$ & $6900 \\pm 600$\n",
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_basic_O1\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_2.csv (size 2 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_4.csv (size 4 < 256)', 'results_c_64.csv (size 64 < 256)', 'results_c_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.00710 \\pm 0.00008$ & $0.150 \\pm 0.017$ & $2.16 \\pm 0.07$ & $88 \\pm 9$ & $782 \\pm 2$ & $6900 \\pm 600$\n",
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_basic_O2\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_2.csv (size 2 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_4.csv (size 4 < 256)', 'results_c_64.csv (size 64 < 256)', 'results_c_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.006862 \\pm 0.000019$ & $0.127 \\pm 0.009$ & $2.11 \\pm 0.07$ & $90 \\pm 7$ & $777.5 \\pm 1.5$ & $7000 \\pm 500$\n",
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_basic_O3\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 13 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 7 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_2.csv (size 2 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_4.csv (size 4 < 256)', 'results_c_64.csv (size 64 < 256)', 'results_c_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.00675 \\pm 0.00010$ & $0.082 \\pm 0.014$ & $2.27 \\pm 0.11$ & $86 \\pm 7$ & $872.4 \\pm 1.8$ & $6900 \\pm 600$\n"
     ]
    }
   ],
   "source": [
    "results_dir1 = '../python/basic'\n",
    "results_dir2 = '../python/numpy'\n",
    "results_dir3 = '../C/DGEMM_basic_O0'\n",
    "results_dir4 = '../C/DGEMM_basic_O1'\n",
    "results_dir5 = '../C/DGEMM_basic_O2'\n",
    "results_dir6 = '../C/DGEMM_basic_O3'\n",
    "\n",
    "\n",
    "# --- Basic Call (using most defaults) ---\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir1, verbose=False)\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir2, verbose=False)\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir3, verbose=False)\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir4, verbose=False)\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir4, verbose=False)\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir5, verbose=False)\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir6, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_SIMD\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 12 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 6 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_4.csv (size 4 < 256)', 'results_c_64.csv (size 64 < 256)', 'results_c_8.csv (size 8 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.00218 \\pm 0.00003$ & $0.034 \\pm 0.002$ & $0.55 \\pm 0.03$ & $6.5 \\pm 1.4$ & $175.5 \\pm 0.3$ & $1757 \\pm 2$\n"
     ]
    }
   ],
   "source": [
    "results_dir = '../C/DGEMM_SIMD'\n",
    "\n",
    "\n",
    "# --- Basic Call (using most defaults) ---\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_unrolling\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 10 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 4 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_16.csv (size 16 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_64.csv (size 64 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.00129 \\pm 0.00004$ & $0.0127 \\pm 0.0009$ & $0.134 \\pm 0.013$ & $2.41 \\pm 0.17$ & $49.21 \\pm 0.09$ & $431.6 \\pm 0.2$\n"
     ]
    }
   ],
   "source": [
    "results_dir = '../C/DGEMM_unrolling'\n",
    "# --- Basic Call (using most defaults) ---\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Searched in: c:\\Duds\\DuduClean\\ArquivosVScodePastaManual\\UFRJ\\periodo3\\ArqComp\\Pratica\\DGEMM\\C\\DGEMM_blocking\n",
      "Using pattern: results_*_[0-9]*.csv\n",
      "Attempted to process 9 files.\n",
      "Successfully processed data for 6 unique matrix sizes from 6 files.\n",
      "Skipped 3 files/entries.\n",
      "  Skipped items list: ['results_c_128.csv (size 128 < 256)', 'results_c_32.csv (size 32 < 256)', 'results_c_64.csv (size 64 < 256)']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Results ---\n",
      "Matrix Sizes Included in Output: [256, 512, 1024, 2048, 4096, 8192]\n",
      "\n",
      "Final Output Line (using separator ' & '):\n",
      "$0.00108 \\pm 0.00006$ & $0.0093 \\pm 0.0002$ & $0.076 \\pm 0.003$ & $0.646 \\pm 0.006$ & $6.725 \\pm 0.017$ & $56.63 \\pm 0.06$\n"
     ]
    }
   ],
   "source": [
    "results_dir = '../C/DGEMM_blocking'\n",
    "# --- Basic Call (using most defaults) ---\n",
    "latex_string, raw_data, processed, skipped = process_and_format_results(results_dir, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
